{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、昨日回顾\n",
    "\n",
    "- 1.概述什么是http协议\n",
    "    - 服务器和客户端之前进行交互的一种形式\n",
    "- 2.爬虫的分类\n",
    "    - 通用爬虫: 爬取一整张页面\n",
    "    - 聚焦爬虫: 爬取页面中指定的内容\n",
    "    - 增量式爬虫: 用来监测网站数据更新的情况, 只爬取网站最新更新的数据\n",
    "- 3.爬虫中常用头信息\n",
    "    - 请求头:\n",
    "        - User-Agent: 请求载体的身份标识\n",
    "        - Connection: 连接, 可以赋的值为close\n",
    "    - 响应头:\n",
    "        - Content-Type: 就是服务器端响应回客户端的数据类型\n",
    "- 4.https中涉及到的三种加密方式\n",
    "    - 对称密钥加密方式\n",
    "    - 非对称密钥加密方式\n",
    "    - 证书密钥加密\n",
    "- 5.requests模块的作用及编码流程\n",
    "    - requests模块的作用是模拟浏览器发送请求\n",
    "    - 编码流程:\n",
    "        - (1)指定URL\n",
    "        - (2)发起请求\n",
    "        - (3)获取响应数据\n",
    "        - (4)持久化存储\n",
    "- 6.requests如何进行参数封装,为什么要进行参数封装\n",
    "    - 在我们请求页面进行爬取数据时,有的参数不能写死,需要动态传入,就必须得进行请求参数的封装,而且要封装到字典当中,再将字典给作用到相关     请求的参数中就可以了,在GET里面是params,POST请求中是data\n",
    "- 7.简述目前接触到的反爬机制及其反反爬策略\n",
    "    - (1)robots协议\n",
    "    - (2)User-Agent请求载体的身份标识\n",
    "    - (3)动态加载的数据\n",
    "- 8.什么是动态加载数据\n",
    "    - 如果想对页面进行爬取的话,一定要注意当前页面中可能会涉及到动态加载的数据,这些动态数据是我们通过URL请求无法直接获取到的,而是通过页     面中某种操作(比如滚轮下滑、页码点击)激活的Ajax请求才能获取到。\n",
    "- 9.爬取图片的两种方式\n",
    "    - 使用requests\n",
    "    - urllib模块request中urlretrive\n",
    "- 10.数据解析的基本原理\n",
    "    - 标签的定位\n",
    "    - 取文本或取属性\n",
    "- 11.bs4解析原理\n",
    "    - 实例化一个BeautifulSoup对象, 必须把即将被解析的页面源码加载到该对象中\n",
    "    - 调用该对象中相关的属性或者方法进行标签的定位和内容的提取\n",
    "- 12.BeautifulSoup对象实例化方式\n",
    "    - 本地文件：\n",
    "         - soup = BeautifulSoup(open('本地文件'), 'lxml')\n",
    "    - 网络文件：\n",
    "         - soup = BeautifulSoup('字符串类型或者字节类型', 'lxml')\n",
    "- 13.xpath解析原理\n",
    "    - 实例化一个etree对象, 且将解析的页面源码加载到该对象中\n",
    "    - 使用该对象中的xpath方法结合着xpath表达式进行标签定位和数据解析提取\n",
    "- 14.etree对象实例化的方式\n",
    "    - 本地文件：\n",
    "         - tree = etree.parse('file_path')\n",
    "    - 网络文件：\n",
    "         - tree = etree.HTML(page_text)\n",
    "\n",
    "- 15.面试题：如何爬取携带标签的指定页面内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、今日内容\n",
    "\n",
    "- 1.打码平台\n",
    "- 2.代理的使用\n",
    "- 3.模拟登录\n",
    "- 4.selenium\n",
    "- 5.单线程+异步爬虫\n",
    "- 6.多任务异步协程\n",
    "- 7.scrapy框架初识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
